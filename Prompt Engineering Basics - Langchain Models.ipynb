{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7381b360",
   "metadata": {},
   "source": [
    "# Prompt Engineering Basics - Langchain Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048348b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f44be9f",
   "metadata": {},
   "source": [
    "# Example - 1: Asking Data Science concept Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b4e7eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want you to act as a data scientist and in an easy way, explain the basics of NLP to non-tech people.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "demo_template ='''I want you to act as a data scientist and in an easy way, explain the basics of {ds_concept} to non-tech people.'''\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    input_variables=['ds_concept'],\n",
    "    template=demo_template\n",
    "    )\n",
    "\n",
    "prompt.format(ds_concept='NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99bcf2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "#chains to execute prompt template\n",
    "from langchain.chains import LLMChain\n",
    "llm = OpenAI(temperature=0.7)\n",
    "chain = LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45f91bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nExploratory Data Analysis (EDA) is a process used by data scientists to better understand a dataset. It involves exploring and analyzing data to find patterns, trends, and relationships that can help us make sense of the information.\\n\\nOne important aspect of EDA is cleaning the data. This means checking for any errors, missing values, or outliers that could affect our analysis. For example, if we were looking at a dataset of people's ages, we would want to make sure there are no values that don't make sense (like someone being listed as 200 years old) and that all the data is in the same format (like all ages listed in years instead of some in months).\\n\\nOnce the data is cleaned, we can start to visualize it. This means creating charts, graphs, and other visual representations to help us see patterns and trends in the data. For example, we might create a bar graph to compare the number of males and females in our dataset or a line graph to see how a certain value changed over time.\\n\\nEDA also involves looking at different statistical measures, like mean, median, and standard deviation, to understand the distribution of the data. This can help us understand if the data is skewed in one direction or if there are any outliers that could affect\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('Exploratory Data Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7c32d",
   "metadata": {},
   "source": [
    "# Example - 2: Language Translator Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93344061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Translate the sentence 'How are you' into a french\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiinput prompt\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "demo_template ='''Translate the sentence '{sentence}' into a {targetlanguage}'''\n",
    "\n",
    "translate_prompt=PromptTemplate(\n",
    "    input_variables=['sentence','targetlanguage'],\n",
    "    template=demo_template\n",
    "    )\n",
    "#how input is formatted\n",
    "translate_prompt.format(sentence=\"How are you\",targetlanguage='french')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bedcbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "llm = OpenAI(temperature=0.7)\n",
    "lang_chain = LLMChain(llm=llm,prompt=translate_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71f3e708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ' how are you',\n",
       " 'targetlanguage': 'tamil',\n",
       " 'text': '\\n\\nநீங்கள் எப்படி இருக்கிறீர்கள்? (Nīṅkaḷ eppaṭi irukkiṟīrgaḷ?)'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to run the prompt with multiinput - key value pairs (dict)\n",
    "lang_chain({'sentence':' how are you','targetlanguage':'tamil'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dddd9de",
   "metadata": {},
   "source": [
    "# Example - 3: Training the LLM Model with few examples -FewShotPromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34ae29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "# First, create the list of few shot examples.\n",
    "#examples to train LLM models\n",
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "]\n",
    "\n",
    "# Next, we specify the template to format the examples we have provided.\n",
    "# We use the `PromptTemplate` class for this.\n",
    "example_formatter_template = \"\"\"Word: {word}\n",
    "Antonym: {antonym}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1c1e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we create the `FewShotPromptTemplate` object.\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    # These are the examples we want to insert into the prompt.\n",
    "    examples=examples,\n",
    "    # This is how we want to format the examples when we insert them into the prompt.\n",
    "    example_prompt=example_prompt,\n",
    "    # The prefix is some text that goes before the examples in the prompt.\n",
    "    # Usually, this consists of intructions.\n",
    "    prefix=\"Give the antonym of every input\\n\",\n",
    "    # The suffix is some text that goes after the examples in the prompt.\n",
    "    # Usually, this is where the user input will go\n",
    "    suffix=\"Word: {input}\\nAntonym: \",\n",
    "    # The input variables are the variables that the overall prompt expects.\n",
    "    input_variables=[\"input\"],\n",
    "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
    "    example_separator=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43c04551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "Word: big\n",
      "Antonym: \n"
     ]
    }
   ],
   "source": [
    "#input format for LLM model\n",
    "print(few_shot_prompt.format(input='big'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c55c4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'big', 'text': 'small'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=LLMChain(llm=llm,prompt=few_shot_prompt)\n",
    "chain({'input':\"big\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
